
# ===============================
# üåê Insight Layer .env.example
# ===============================

# === üîë API Keys ===
# Required if using OpenAI for LLM parsing, summarization, or review
OPENAI_API_KEY=your-openai-key-here

# === ‚öôÔ∏è Agent Configuration ===

# Optional: Path to the YAML config used by LangGraph agent
INSIGHT_AGENT_CONFIG=configs/insight_agent_config.yaml

# Optional: Confidence threshold (1‚Äì10) to accept auto-inferred metadata
MIN_CONFIDENCE_FOR_META=6

# Optional: Toggle to disable LLM summarization (fallback will be used)
USE_LLM=true

# Optional: Toggle verbose logging output
VERBOSE=true

# Optional: Log every task to /data/trace_logs
TRACE_ENABLED=true

# Optional: Automatically group new insights into a bundle by topic
AUTO_BUNDLE=true

# Optional: Filter memory to team_only (vs public insights)
CONFIDENTIAL_ONLY=false

# Optional: Minimum importance score required to reuse an insight
MIN_IMPORTANCE_SCORE=5.0

# Optional: Max age (in days) to reuse old insights
MAX_INSIGHT_AGE_DAYS=180
